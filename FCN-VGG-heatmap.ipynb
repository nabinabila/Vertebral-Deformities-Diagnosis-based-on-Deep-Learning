{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import models\n",
    "from torchvision.models.vgg import VGG\n",
    "\n",
    "device = 'cuda:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a test\n",
    "\n",
    "image = cv.imread(\"/disk1/jklu/ClearSpineData/CAT_only_256_512/images/00001_AP.png\", cv.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-defined dataset\n",
    "\n",
    "class SpineDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, path):\n",
    "    \n",
    "        image_files = os.listdir(path + \"/images/\")\n",
    "        image_files.sort(key=lambda x:int(x[:5]))\n",
    "        \n",
    "        txt_files = os.listdir(path + \"/txt/\")\n",
    "        txt_files.sort(key=lambda x:int(x[:5]))\n",
    "\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.heatmaps = []\n",
    "        \n",
    "        for img in image_files:\n",
    "\n",
    "            image = cv.imread(path + \"/images/\" + img, cv.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            image = np.reshape(image, (1, image.shape[0], image.shape[1]))\n",
    "            \n",
    "            img = torch.from_numpy(image).type(torch.FloatTensor)\n",
    "            \n",
    "            self.images.append(img)\n",
    "\n",
    "        for txt in txt_files:\n",
    "            src_txt = open(path + \"/txt/\" + txt, 'r')\n",
    "            points = np.array(src_txt.read().split()).astype(np.float)\n",
    "            \n",
    "            pts = torch.from_numpy(points).type(torch.FloatTensor)\n",
    "            \n",
    "            self.labels.append(points)\n",
    "            src_txt.close()\n",
    "            \n",
    "            heatmap = self.generate_heatmap(256, 512, points, 8)            \n",
    "            self.heatmaps.append(heatmap)\n",
    "           \n",
    "        assert len(self.images) == len(self.labels)\n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        img = self.images[index]\n",
    "        label = self.labels[index]\n",
    "        heatmap = self.heatmaps[index]\n",
    "        return img, label, heatmap\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def generate_heatmap(self, width, height, coordinate_array, sigma):\n",
    "        \n",
    "        landmark_num = len(coordinate_array) // 2\n",
    "        \n",
    "        heat_map = -128 * np.ones((landmark_num, height, width), np.float)\n",
    "        \n",
    "        for index in range(landmark_num):\n",
    "            x = coordinate_array[2 * index]\n",
    "            y = coordinate_array[2 * index + 1]\n",
    "        \n",
    "            for xx in range(int(x) - 3 * sigma, int(x) + 3 * sigma + 1):\n",
    "                for yy in range(int(y) - 3 * sigma, int(y) + 3 * sigma + 1):\n",
    "                    value = 256 * np.exp(-( (x-xx)**2 + (y-yy)**2) / (2*sigma**2)) - 128\n",
    "                    if 0 <= xx < width and 0 <= yy < height:\n",
    "                        heat_map[index, yy, xx] = value\n",
    "        \n",
    "        return heat_map\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the train and test data loader\n",
    "\n",
    "dataset = SpineDataSet(\"/disk2/jklu/ClearSpineData/CAT_only_256_512\")\n",
    "\n",
    "batch = 4\n",
    "train_num = 400\n",
    "test_num = 17\n",
    "\n",
    "train_data, test_data = torch.utils.data.random_split(dataset, [train_num, test_num])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "print(\"number of batches(training): \", len(train_loader))\n",
    "print(\"number of batches(testing): \",len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = {\n",
    "    'vgg11': ((0, 3), (3, 6),  (6, 11),  (11, 16), (16, 21)),\n",
    "    'vgg13': ((0, 5), (5, 10), (10, 15), (15, 20), (20, 25)),\n",
    "    'vgg16': ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)),\n",
    "    'vgg19': ((0, 5), (5, 10), (10, 19), (19, 28), (28, 37))\n",
    "}\n",
    "\n",
    "# Vgg-Net config \n",
    "# Vgg网络结构配置\n",
    "cfg = {\n",
    "    'vgg11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'vgg13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'vgg16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'vgg19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "# make layers using Vgg-Net config(cfg)\n",
    "# 由cfg构建vgg-Net\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 1\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class VGGNet(VGG):\n",
    "    def __init__(self, pretrained=False, model='vgg16', requires_grad=True, remove_fc=True, show_params=False):\n",
    "        super().__init__(make_layers(cfg[model]))\n",
    "        self.ranges = ranges[model]\n",
    "\n",
    "        if pretrained:\n",
    "            exec(\"self.load_state_dict(models.%s(pretrained=True).state_dict())\" % model)\n",
    "\n",
    "        if not requires_grad:\n",
    "            for param in super().parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # delete redundant fully-connected layer params, can save memory\n",
    "        # 去掉vgg最后的全连接层(classifier)\n",
    "        if remove_fc:  \n",
    "            del self.classifier\n",
    "\n",
    "        if show_params:\n",
    "            for name, param in self.named_parameters():\n",
    "                print(name, param.size())\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = {}\n",
    "        # get the output of each maxpooling layer (5 maxpool in VGG net)\n",
    "        for idx, (begin, end) in enumerate(self.ranges):\n",
    "        #self.ranges = ((0, 5), (5, 10), (10, 17), (17, 24), (24, 31)) (vgg16 examples)\n",
    "            for layer in range(begin, end):\n",
    "                x = self.features[layer](x)\n",
    "            output[\"x%d\"%(idx+1)] = x\n",
    "\n",
    "        return output\n",
    "    \n",
    "    \n",
    "\n",
    "class FCNs(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_net, n_class):\n",
    "        super().__init__()\n",
    "        self.n_class = n_class\n",
    "        self.pretrained_net = pretrained_net\n",
    "        self.relu    = nn.ReLU(inplace=True)\n",
    "        self.deconv1 = nn.ConvTranspose2d(512, 512, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn1     = nn.BatchNorm2d(512)\n",
    "        self.deconv2 = nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn2     = nn.BatchNorm2d(256)\n",
    "        self.deconv3 = nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn3     = nn.BatchNorm2d(128)\n",
    "        self.deconv4 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn4     = nn.BatchNorm2d(64)\n",
    "        self.deconv5 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, dilation=1, output_padding=1)\n",
    "        self.bn5     = nn.BatchNorm2d(32)\n",
    "        self.classifier = nn.Conv2d(32, n_class, kernel_size=1) \n",
    "        # classifier is 1x1 conv, to reduce channels from 32 to n_class\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.pretrained_net(x)\n",
    "        x5 = output['x5']  \n",
    "        x4 = output['x4']  \n",
    "        x3 = output['x3']  \n",
    "        x2 = output['x2']  \n",
    "        x1 = output['x1']  \n",
    "\n",
    "        score = self.bn1(self.relu(self.deconv1(x5)))     \n",
    "        score = score + x4                                \n",
    "        score = self.bn2(self.relu(self.deconv2(score)))  \n",
    "        score = score + x3                                \n",
    "        score = self.bn3(self.relu(self.deconv3(score)))  \n",
    "        score = score + x2                                \n",
    "        score = self.bn4(self.relu(self.deconv4(score)))  \n",
    "        score = score + x1                                \n",
    "        score = self.bn5(self.relu(self.deconv5(score)))  \n",
    "        score = self.classifier(score)                    \n",
    "\n",
    "        return score  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = VGGNet(requires_grad=True, show_params=True)\n",
    "\n",
    "net = FCNs(pretrained_net=vgg_model, n_class=4)\n",
    "#net = torch.load('/disk1/jklu/models/VGG-FCN.pth')\n",
    "\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "\n",
    "#heatmap = dataset.generate_heatmap(256, 512, [200, 300], 10)\n",
    "#print(heatmap.shape)\n",
    "#plt.imshow(heatmap[0])\n",
    "# print(dataset.generate_heatmap(256, 512, 200, 300, 10))\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels, heatmaps = dataiter.next()\n",
    "\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "out = net(images)\n",
    "print(out.shape)\n",
    "\n",
    "# show images\n",
    "#plt.imshow(labels[0, 0] + labels[0, 1] + labels[0, 2] + 3*labels[0, 3])\n",
    "#plt.imshow(images[0].numpy().squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here define loss function\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "#lr_func = lambda epoch: epoch * 1\n",
    "#scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_func)\n",
    "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',factor=0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute loss\n",
    "\n",
    "def compute_loss(net, data_loader):\n",
    "    loss_sum = 0\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        images, _, heatmaps = data\n",
    "        images = images.to(device)\n",
    "        heatmaps = heatmaps.to(device)\n",
    "        outputs = net(images)\n",
    "        \n",
    "        loss = criterion(outputs.float(), heatmaps.float()) \n",
    "        loss_sum += loss.item()\n",
    "       \n",
    "    return loss_sum / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training\n",
    "\n",
    "epoch_num = 70\n",
    "\n",
    "loss1 = []\n",
    "loss2 = []\n",
    "\n",
    "\n",
    "for epoch in range(epoch_num):  # loop over the dataset multiple times\n",
    "    loss_sum = 0\n",
    "    \n",
    "    test_loss = compute_loss(net, test_loader)\n",
    "    loss2.append(test_loss)\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "                \n",
    "        # get the inputs\n",
    "        inputs, _, heatmaps = data\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        heatmaps = heatmaps.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "    \n",
    "        \n",
    "        loss = criterion(outputs.float(), heatmaps.float())\n",
    "        \n",
    "        loss_sum += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "    #scheduler.step(loss.item())\n",
    "    \n",
    "    #train_loss = compute_loss(net, train_loader)\n",
    "    train_loss = loss_sum / len(train_loader)\n",
    "    loss1.append(train_loss)\n",
    "\n",
    "    \n",
    "    print(\"epoch number\", epoch+1, \"train_loss\", train_loss, \"test_loss\", test_loss)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = range(1, epoch_num+1)\n",
    "\n",
    "plt.plot(x, loss1, label=\"training loss\")\n",
    "plt.plot(x, loss2, label=\"testing loss\")\n",
    "plt.xlabel(\"epoch number\")\n",
    "#plt.xticks(np.linspace(1,epoch_num,epoch_num))\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(\"loss graph\")\n",
    "plt.legend()\n",
    "plt.savefig(\"./VGG-FCN.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, '/disk1/jklu/models/VGG-FCN.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CVimshow2pltimshow(cv_img):\n",
    "    \"\"\"\n",
    "    cv_img: [3, height, width], BGR, numpy array, int(0-255)\n",
    "    \"\"\"\n",
    "    b,g,r = cv.split(cv_img)  \n",
    "    plt_img = cv.merge([r,g,b]).astype(np.int)\n",
    "    return plt_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize result (heat map):\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = (15, 15)\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "images, labels, heatmaps = dataiter.next()\n",
    "batch, channel, height, width = images.shape\n",
    "\n",
    "ret = net(images.to(device)).to('cpu').detach().numpy()\n",
    "_, point, _, _ = ret.shape\n",
    "\n",
    "\n",
    "for i in range(batch):\n",
    "    sample = images[i].numpy().squeeze(0)\n",
    "    sample_BGR = cv.cvtColor(sample, cv.COLOR_GRAY2BGR)\n",
    "    \n",
    "    label = labels[i]\n",
    "    for j in range(len(label) // 4):\n",
    "        cv.line(sample_BGR, (int(label[4*j]), int(label[4*j+1])), \n",
    "                (int(label[4*j+2]), int(label[4*j+3])), (255, 0, 0), 1)\n",
    "    sample_RGB = CVimshow2pltimshow(sample_BGR)\n",
    "    plt.subplot(2,4,2*i+1)\n",
    "    plt.imshow(sample_RGB)    \n",
    "    \n",
    "    \n",
    "    img = ret[i, 0] + ret[i, 1] + ret[i, 2] + ret[i, 3]\n",
    "\n",
    "    norm_heatmap = np.zeros(img.shape, dtype=np.int8)\n",
    "    norm_heatmap = cv.normalize(img, norm_heatmap, 0, 255, norm_type=cv.NORM_MINMAX).astype(np.int8)\n",
    "    \n",
    "    plt.subplot(2,4,2*i+2)\n",
    "    plt.imshow(img)  \n",
    "    \n",
    "    \"\"\"\n",
    "    norm_heatmap = np.zeros(img.shape, dtype=np.int8)\n",
    "    \n",
    "    norm_heatmap = cv.normalize(img, norm_heatmap, 0, 255, norm_type=cv.NORM_MINMAX).astype(np.int8)\n",
    "    combine = np.zeros((height, width, 3), np.int8)\n",
    "    \n",
    "\n",
    "    combine[:, :, 2] = norm_heatmap\n",
    "    \n",
    "    #print(combine)\n",
    "    \n",
    "    for j in range(len(label) // 4):\n",
    "        \n",
    "        #print(label)\n",
    "        \n",
    "        cv.line(combine, (0,0), (0, 10), (0,0,0), 2)\n",
    "        \n",
    "        print(combine[1,1])\n",
    "        \n",
    "        cv.line(combine, (int(label[4*j]), int(label[4*j+1])), \n",
    "                (int(label[4*j+2]), int(label[4*j+3])), (0, 0, 255), 2) \n",
    "        \n",
    "    plt_img = CVimshow2pltimshow(combine)\n",
    "    \n",
    "    plt.subplot(2,4,4+i+1)\n",
    "    plt.imshow(plt_img)    \n",
    "    \"\"\"\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array([[1,2,3,4],[5,6,7,8]])\n",
    "    \n",
    "norm_heatmap = np.zeros(img.shape, dtype=np.int)\n",
    "    \n",
    "norm_heatmap = cv.normalize(img, norm_heatmap, 0, 256, norm_type=cv.NORM_MINMAX).get()\n",
    "\n",
    "print(norm_heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
