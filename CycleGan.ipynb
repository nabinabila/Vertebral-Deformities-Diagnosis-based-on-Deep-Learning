{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d8RWhDKEgT-"
      },
      "source": [
        "# Style transfer using GAN\n",
        "This notebook will be used to prepare the capstone project 'Style transfer using GAN'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-XrP8-dEgUE"
      },
      "outputs": [],
      "source": [
        "#Import all the required libraries\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "import numpy as np\n",
        "from numpy import asarray\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import load_img\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30jjZeV-EgUK"
      },
      "source": [
        "## Data understanding\n",
        "Import the images & create two seperate datasets. The input shape for image should be (256, 256)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHADNCwJEgUs"
      },
      "outputs": [],
      "source": [
        "# load and resize images\n",
        "def load_images(path, size=(256,256)):\n",
        "    data_list = list()\n",
        "\n",
        "    for filename in listdir(path):\n",
        "        pixels = load_img(path + filename, target_size=size)\n",
        "        # convert to numpy array\n",
        "        pixels = img_to_array(pixels)\n",
        "        # store the data\n",
        "        data_list.append(pixels)\n",
        "    return asarray(data_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcV1E2ZqEgUv",
        "outputId": "def3d6a4-dec7-4567-abba-16c0f448a10c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (256, 256, 1), types: tf.float32>"
            ]
          },
          "execution_count": 210,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load dataset tr1\n",
        "import tensorflow as tf\n",
        "tr1_data = load_images('dataset/Tr1/TrainT1/') #write your code to create the dataset from image directory\n",
        "tr1_data = tf.image.rgb_to_grayscale(tr1_data) #convert to grayscale\n",
        "tr1= tf.data.Dataset.from_tensor_slices(tf.convert_to_tensor(tr1_data))\n",
        "tr1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VMjQdWlEgUw",
        "outputId": "ebb93bce-a8da-4f94-8b75-1442e2bdedf0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: (256, 256, 1), types: tf.float32>"
            ]
          },
          "execution_count": 211,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load dataset tr2\n",
        "tr2_data = load_images('dataset/Tr2/TrainT2/') #write your code to create the dataset from image directory\n",
        "tr2_data = tf.image.rgb_to_grayscale(tr2_data) #convert to grayscale\n",
        "tr2= tf.data.Dataset.from_tensor_slices(tf.convert_to_tensor(tr2_data))\n",
        "tr2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDmGkOM2EgUz"
      },
      "source": [
        "## Image Processing\n",
        "1.Create a function to process your images with normalisation\n",
        "\n",
        "2.Apply the function to both the datasets\n",
        "\n",
        "3.Visualise the MRI images after processing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lm5AKT-GEgU2"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 1000\n",
        "BATCH_SIZE = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1KLWFLFEgU3"
      },
      "outputs": [],
      "source": [
        "# normalizing the images to [-1, 1]\n",
        "def normalize(image):\n",
        "    image =  tf.cast(image, tf.float32)\n",
        "    image= (image / 127.5) - 1\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyaP4hLJ8b4W"
      },
      "outputs": [],
      "source": [
        "def preprocess_image_train(image):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = normalize(image)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsajGXxd5JkZ"
      },
      "outputs": [],
      "source": [
        "# process both classes of MRI images\n",
        "import tensorflow as tf\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "tr1 = tr1 .map(preprocess_image_train, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "tr2 = tr2 .map(preprocess_image_train, num_parallel_calls=AUTOTUNE).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3MhJ3zVLPan"
      },
      "outputs": [],
      "source": [
        "sample_tr1 = next(iter(tr1))\n",
        "sample_tr2 = next(iter(tr2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8FwfgXJEgU7"
      },
      "source": [
        "## Model Building & Training\n",
        "The architecture of generator is a modified U-Net.\n",
        "\n",
        "1.Create your Generator & Discriminator\n",
        "\n",
        "2.Define the loss functions\n",
        "\n",
        "3.Create the train_step function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZOlkjYOEgU8"
      },
      "outputs": [],
      "source": [
        "class InstanceNormalization(tf.keras.layers.Layer):\n",
        "    def __init__(self, epsilon=1e-5):\n",
        "        super(InstanceNormalization, self).__init__()\n",
        "        self.epsilon = epsilon\n",
        "    def build(self, input_shape):\n",
        "        self.scale = self.add_weight(\n",
        "            name='scale',\n",
        "            shape=input_shape[-1:],\n",
        "            initializer=tf.random_normal_initializer(1., 0.02),\n",
        "            trainable=True)\n",
        "        self.offset = self.add_weight(\n",
        "            name='offset',\n",
        "            shape=input_shape[-1:],\n",
        "            initializer='zeros',\n",
        "            trainable=True)\n",
        "    def call(self, x):\n",
        "        mean, variance = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
        "        inv = tf.math.rsqrt(variance + self.epsilon)\n",
        "        normalized = (x - mean) * inv\n",
        "        return self.scale * normalized + self.offset\n",
        "\n",
        "def downsample(filters, size, apply_norm=True):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    result = tf.keras.Sequential()\n",
        "    result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n",
        "                                      kernel_initializer=initializer, use_bias=False))\n",
        "    if apply_norm:\n",
        "        result.add(InstanceNormalization())\n",
        "    result.add(tf.keras.layers.LeakyReLU())\n",
        "    return result\n",
        "\n",
        "def upsample(filters, size, apply_dropout=False):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    result = tf.keras.Sequential()\n",
        "    result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding='same',\n",
        "                                               kernel_initializer=initializer, use_bias=False))\n",
        "    result.add(InstanceNormalization())\n",
        "    if apply_dropout:\n",
        "        result.add(tf.keras.layers.Dropout(0.5))\n",
        "    result.add(tf.keras.layers.ReLU())\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bynjBw6EgVD"
      },
      "outputs": [],
      "source": [
        "def unet_generator():\n",
        "\n",
        "    down_stack = [\n",
        "      downsample(64, 4, apply_norm=False),\n",
        "      downsample(128, 4),\n",
        "      downsample(256, 4),\n",
        "      downsample(512, 4),\n",
        "      downsample(512, 4),\n",
        "      downsample(512, 4),\n",
        "      downsample(512, 4),\n",
        "      downsample(512, 4),\n",
        "    ]\n",
        "                  #create a stack of downsample models\n",
        "    up_stack = [\n",
        "      upsample(512, 4, apply_dropout=True),\n",
        "      upsample(512, 4, apply_dropout=True),\n",
        "      upsample(512, 4, apply_dropout=True),\n",
        "      upsample(512, 4),\n",
        "      upsample(256, 4),\n",
        "      upsample(128, 4),\n",
        "      upsample(64, 4),\n",
        "               ] #create a stack of upsample models\n",
        "\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    last = tf.keras.layers.Conv2DTranspose(1, 4, strides=2, padding='same', kernel_initializer=initializer,\n",
        "                                           activation='tanh')\n",
        "    concat = tf.keras.layers.Concatenate()\n",
        "    inputs = tf.keras.layers.Input(shape=[None, None, 1])\n",
        "    x = inputs\n",
        "    # Downsampling through the model\n",
        "    skips = []\n",
        "    for down in down_stack:\n",
        "        x = down(x)\n",
        "        skips.append(x)\n",
        "    skips = reversed(skips[:-1])\n",
        "    # Upsampling and establishing the skip connections\n",
        "    for up, skip in zip(up_stack, skips):\n",
        "        x = up(x)\n",
        "        x = concat([x, skip])\n",
        "    x = last(x)\n",
        "    return tf.keras.Model(inputs=inputs, outputs=x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siLc0s0qEgVF"
      },
      "outputs": [],
      "source": [
        "generator_g = unet_generator() #initialise the generator\n",
        "generator_f = unet_generator() #initialise the generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zajmhKBxEgVG"
      },
      "outputs": [],
      "source": [
        "def discriminator():\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    inp = tf.keras.layers.Input(shape=[None, None, 1], name='input_image')\n",
        "    x = inp\n",
        "    down1 = downsample(64, 4,  False)(x)  #write your code to downsample X\n",
        "    down2 = downsample(128, 4)(down1)     #write your code to downsample down1\n",
        "    down3 = downsample(256, 4)(down2)     #write your code to downsample down2\n",
        "    zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3) # (bs, 34, 34, 256)\n",
        "    conv = tf.keras.layers.Conv2D(512, 4, strides=1, kernel_initializer=initializer,\n",
        "                                  use_bias=False)(zero_pad1) # (bs, 31, 31, 512)\n",
        "    norm1 = InstanceNormalization()(conv)\n",
        "    leaky_relu = tf.keras.layers.LeakyReLU()(norm1)\n",
        "    zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu) # (bs, 33, 33, 512)\n",
        "    last = tf.keras.layers.Conv2D(1, 4, strides=1, kernel_initializer=initializer)(zero_pad2) # (bs, 30, 30, 1)\n",
        "\n",
        "    return tf.keras.Model(inputs=inp, outputs=last) #create the model using input & output layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ju9Wyw87MRW"
      },
      "outputs": [],
      "source": [
        "discriminator_x = discriminator() #initialise the discriminator\n",
        "discriminator_y = discriminator() #initialise the discriminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyhxTuvJyIHV"
      },
      "outputs": [],
      "source": [
        "LAMBDA = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1Xbz5OaLj5C"
      },
      "outputs": [],
      "source": [
        "# Using Binarycross entropy with logits true\n",
        "loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wkMNfBWlT-PV"
      },
      "outputs": [],
      "source": [
        "# calculating discriminator loss by summing the real and generated\n",
        "def discriminator_loss(real, generated):\n",
        "    real_loss = loss_obj(tf.ones_like(real), real) #write your code here\n",
        "    generated_loss = loss_obj(tf.zeros_like(generated), generated) #write your code here\n",
        "    total_disc_loss = real_loss + generated_loss #write your code here\n",
        "    return total_disc_loss * 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90BIcCKcDMxz"
      },
      "outputs": [],
      "source": [
        "def generator_loss(generated):\n",
        "    return loss_obj(tf.ones_like(generated), generated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMpVGj_sW6Vo"
      },
      "outputs": [],
      "source": [
        "def calc_cycle_loss(real_image, cycled_image):\n",
        "    loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image)) #write your code here\n",
        "    return LAMBDA * loss1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05ywEH680Aud"
      },
      "outputs": [],
      "source": [
        "def identity_loss(real_image, same_image):\n",
        "    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
        "    return LAMBDA * 0.5 * loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWCn_PVdEJZ7"
      },
      "outputs": [],
      "source": [
        "# Optimizer with learning rate 0.0001 for generator and discriminator\n",
        "generator_g_optimizer = tf.keras.optimizers.Adam(0.0001, beta_1=0.5)\n",
        "generator_f_optimizer = tf.keras.optimizers.Adam(0.0001, beta_1=0.5)\n",
        "\n",
        "discriminator_x_optimizer = tf.keras.optimizers.Adam(0.0001, beta_1=0.5)\n",
        "discriminator_y_optimizer = tf.keras.optimizers.Adam(0.0001, beta_1=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Lwvh40VEgVP"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 20 #\"Your Number of Epochs Here\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJnftd5sQsv6",
        "outputId": "d0aa8342-c01b-4e99-bcc2-6475fa1492d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Latest checkpoint restored!!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "checkpoint_path = './checkpoints'\n",
        "ckpt = tf.train.Checkpoint(generator_g=generator_g,\n",
        "                           generator_f=generator_f,\n",
        "                           discriminator_x=discriminator_x,\n",
        "                           discriminator_y=discriminator_y,\n",
        "                           generator_g_optimizer=generator_g_optimizer,\n",
        "                           generator_f_optimizer=generator_f_optimizer,\n",
        "                           discriminator_x_optimizer=discriminator_x_optimizer,\n",
        "                           discriminator_y_optimizer=discriminator_y_optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=EPOCHS)\n",
        "\n",
        "# if a checkpoint exists, restore the latest checkpoint.\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print ('Latest checkpoint restored!!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmdVsmvhPxyy"
      },
      "outputs": [],
      "source": [
        "def generate_images(model, test_input, expected_output):\n",
        "    prediction = model(test_input)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    display_list = [test_input[0], prediction[0], expected_output[0]]\n",
        "    title = ['Input Image', 'Predicted Image', 'Expected Image']\n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        plt.title(title[i])\n",
        "        # getting the pixel values between [0, 1] to plot it.\n",
        "        plt.imshow(display_list[i].numpy()[:, :, 0] * 0.5 + 0.5, cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBKUV2sKXDbY"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(real_x, real_y):\n",
        "    # persistent is set to True because the tape is used more than\n",
        "    # once to calculate the gradients.\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        # Generator G translates X -> Y\n",
        "        # Generator F translates Y -> X.\n",
        "        fake_y = generator_g(real_x, training=True)  #write your code to generate images using Generator_g on real_x\n",
        "        cycled_x = generator_f(fake_y, training=True) #write your code to generate images susiing Generator_f on fake_y\n",
        "\n",
        "        fake_x =  generator_f(real_y, training=True) #write your code to generate images using Generator_f on real_y\n",
        "        cycled_y = generator_g(fake_x, training=True) #write your code to generate images using Generator_g on fake_x\n",
        "\n",
        "        # same_x and same_y are used for identity loss.\n",
        "        same_x = generator_f(real_x, training=True) #write your code to generate images using Generator_f on real_x\n",
        "        same_y = generator_g(real_y, training=True) #write your code to generate images using Generator_g on real_y\n",
        "\n",
        "        disc_real_x =  discriminator_x(real_x, training=True) #write your code to discriminate images using Discriminator_x on real_x\n",
        "        disc_real_y = discriminator_y(real_y, training=True) #write your code to discriminate images using Discriminator_y on real_y\n",
        "\n",
        "        disc_fake_x = discriminator_x(fake_x, training=True) #write your code to discriminate images using Discriminator_x on fake_x\n",
        "        disc_fake_y = discriminator_y(fake_y, training=True) #write your code to discriminate images using Discriminator_y on fake_y\n",
        "\n",
        "        # calculate the loss\n",
        "        gen_g_loss = generator_loss(disc_fake_y) # calculate the generator_loss for disc_fake_\n",
        "        gen_f_loss = generator_loss(disc_fake_x) # calculate the generator_loss for disc_fake_X\n",
        "\n",
        "        total_cycle_loss = calc_cycle_loss(real_x, cycled_x) + calc_cycle_loss(real_y, cycled_y)\n",
        " #calculate the total cycle loss\n",
        "\n",
        "        # Total generator loss = adversarial loss + cycle loss\n",
        "        total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(real_y, same_y)\n",
        "        total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(real_x, same_x)\n",
        "\n",
        "        disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x) # calculate the discriminator_loss for disc_fake_x wrt disc_real_x\n",
        "        disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y) # calculate the discriminator_loss foor disc_fake_y wrt disc_real_y\n",
        "\n",
        "    # Calculate the gradients for generator and discriminator\n",
        "    generator_g_gradients = tape.gradient(total_gen_g_loss,\n",
        "                                        generator_g.trainable_variables) #write your code here\n",
        "    generator_f_gradients = tape.gradient(total_gen_f_loss,\n",
        "                                        generator_f.trainable_variables) #write your code here\n",
        "\n",
        "    discriminator_x_gradients = tape.gradient(disc_x_loss,\n",
        "                                            discriminator_x.trainable_variables) #write your code here\n",
        "    discriminator_y_gradients = tape.gradient(disc_y_loss,\n",
        "                                            discriminator_y.trainable_variables)\n",
        " #write your code here\n",
        "\n",
        "    # Apply the gradients to the optimizer\n",
        "\n",
        "    generator_g_optimizer.apply_gradients(zip(generator_g_gradients,\n",
        "                                            generator_g.trainable_variables))\n",
        "\n",
        "    generator_f_optimizer.apply_gradients(zip(generator_f_gradients,\n",
        "                                            generator_f.trainable_variables))\n",
        "\n",
        "    discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients,\n",
        "                                                discriminator_x.trainable_variables))\n",
        "\n",
        "    discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients,\n",
        "                                                discriminator_y.trainable_variables)) #write your code here\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pd4-r_6eEgVT"
      },
      "outputs": [],
      "source": [
        "!rm -rf checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmCFoEyREgVU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}